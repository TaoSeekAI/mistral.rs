name: Build and Publish Docker Images

on:
  push:
    branches: [ master, main, 'vk/*' ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ master, main ]
  workflow_dispatch:
  schedule:
    - cron: '0 2 * * 1'  # Weekly build on Monday at 2 AM UTC

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push:
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        dockerfile: [ 'Dockerfile', 'Dockerfile.cuda-all' ]
        include:
          - dockerfile: 'Dockerfile'
            image-suffix: ''
            platform: 'linux/amd64'
          - dockerfile: 'Dockerfile.cuda-all'
            image-suffix: '-cuda'
            platform: 'linux/amd64'
            requires-gpu: true

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      if: github.event_name != 'pull_request'
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=raw,value=latest,enable={{is_default_branch}}
        flavor: |
          latest=auto
          suffix=${{ matrix.image-suffix }}

    - name: Build and push CPU Docker image
      if: matrix.dockerfile == 'Dockerfile'
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ${{ matrix.dockerfile }}
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        platforms: ${{ matrix.platform }}
        cache-from: |
          type=gha
          type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache
        cache-to: |
          type=gha,mode=max
          type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1

    - name: Build and push CUDA Docker image
      if: matrix.dockerfile == 'Dockerfile.cuda-all'
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ${{ matrix.dockerfile }}
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        platforms: ${{ matrix.platform }}
        build-args: |
          CUDA_COMPUTE_CAP=89
          WITH_FEATURES=cuda,cudnn,flash-attn
          BUILDKIT_INLINE_CACHE=1
        cache-from: |
          type=gha
          type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache-cuda
        cache-to: |
          type=gha,mode=max
          type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache-cuda,mode=max

  test-docker-images:
    name: Test Docker Images
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.event_name != 'pull_request'

    strategy:
      matrix:
        image-suffix: [ '', '-cuda' ]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Pull Docker image
      run: |
        docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest${{ matrix.image-suffix }}

    - name: Create test config
      run: |
        cat > test-config.json << EOF
        {
          "test-model": {
            "Plain": {
              "model_id": "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
            }
          }
        }
        EOF

    - name: Test CPU image
      if: matrix.image-suffix == ''
      run: |
        docker run -d \
          --name mistralrs-test-cpu \
          -p 1234:80 \
          -v $(pwd)/test-config.json:/app/config.json \
          -e RUST_LOG=info \
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest \
          mistralrs-server --port 80 multi-model --config /app/config.json

        # Wait for server to start
        for i in {1..10}; do
          if curl -f http://localhost:1234/v1/models 2>/dev/null; then
            echo "Server is ready"
            break
          fi
          echo "Waiting for server to start... ($i/10)"
          sleep 5
        done

        # Test API endpoints
        curl -f http://localhost:1234/v1/models || exit 1
        curl -f http://localhost:1234/health || exit 1

        # Check logs for any errors
        docker logs mistralrs-test-cpu

        docker stop mistralrs-test-cpu
        docker rm mistralrs-test-cpu

    - name: Test CUDA image
      if: matrix.image-suffix == '-cuda'
      run: |
        # Test if NVIDIA runtime is available
        docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

        docker run -d \
          --name mistralrs-test-gpu \
          --gpus all \
          -p 1234:80 \
          -v $(pwd)/test-config.json:/app/config.json \
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest-cuda \
          mistralrs-server --port 80 multi-model --config /app/config.json

        sleep 30

        # Test API
        curl -f http://localhost:1234/v1/models || exit 1

        docker stop mistralrs-test-gpu
        docker rm mistralrs-test-gpu

  deploy-composite:
    name: Create Composite Docker Image
    runs-on: ubuntu-latest
    needs: [build-and-push, test-docker-images]
    if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v')

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Create composite Dockerfile
      run: |
        cat > Dockerfile.composite << EOF
        FROM ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest-cuda
        LABEL maintainer="${{ github.repository_owner }}"
        LABEL description="Mistral.rs with CUDA support"
        EOF

    - name: Build and push composite image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: Dockerfile.composite
        push: true
        tags: |
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }}
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:composite
        labels: |
          org.opencontainers.image.title=Mistral.rs
          org.opencontainers.image.description=Fast LLM inference server
          org.opencontainers.image.version=${{ github.ref_name }}
          org.opencontainers.image.revision=${{ github.sha }}
        platforms: linux/amd64